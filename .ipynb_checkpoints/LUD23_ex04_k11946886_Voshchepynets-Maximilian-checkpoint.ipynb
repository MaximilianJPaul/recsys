{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ef6227e",
   "metadata": {},
   "source": [
    "*UE Learning from User-generated Data, CP MMS, JKU Linz 2023*\n",
    "# Exercise 4: Evaluation\n",
    "\n",
    "In this exercise we evaluate accuracy of three different RecSys we already implemented. First we implement DCG and nDCG metrics, then we create a simple evaluation framework to compare the three recommenders in terms of nDCG. The implementations for the three recommender systems are provided in a file rec.py and are imported later in the notebook.\n",
    "Please consult the lecture slides and the presentation from UE Session 4 for a recap.\n",
    "\n",
    "Make sure to rename the notebook according to the convention:\n",
    "\n",
    "LUD23_ex03_k<font color='red'><Matr. Number\\></font>_<font color='red'><Surname-Name\\></font>.ipynb\n",
    "\n",
    "for example:\n",
    "\n",
    "LUD23_ex03_k000007_Bond_James.ipynb\n",
    "\n",
    "## Implementation\n",
    "In this exercise, as before, you are reqired to write a number of functions. Only implemented functions are graded. Insert your implementations into the templates provided. Please don't change the templates even if they are not pretty. Don't forget to test your implementation for correctness and efficiency. **Make sure to try your implementations on toy examples and sanity checks.**\n",
    "\n",
    "Please **only use libraries already imported in the notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe8120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da35c1c9",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 1/2</font>: Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9af194",
   "metadata": {},
   "source": [
    "Implement DCG and nDCG in the corresponding templates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6360ca",
   "metadata": {},
   "source": [
    "### DCG Score\n",
    "Implement DCG following the input/output convention:\n",
    "#### Input:\n",
    "* predictions - (not an interaction matrix!) numpy array with recommendations. Row index corresponds to User_id, column index corresponds to the rank of the item mentioned in the sell. Every cell (i,j) contains **item id** recommended to the user (i) on the position (j) in the list. For example:\n",
    "\n",
    "The following predictions structure [[12, 7, 99], [0, 97, 6]] means that the user with id==1 (second row) got recommended item **0** on the top of the list, item **97** on the second place and item **6** on the third place.\n",
    "\n",
    "* test_interaction_matrix - (plain interaction matrix format as before!) interaction matrix constructed from interactions held out as a test set, rows - users, columns - items, cells - 0 or 1\n",
    "\n",
    "* topK - integer - top \"how many\" to consider for the evaluation. By default top 10 items are to be considered\n",
    "\n",
    "#### Output:\n",
    "* DCG score\n",
    "\n",
    "Don't forget, DCG is calculated for every user separately and then the average is returned.\n",
    "\n",
    "\n",
    "<font color='red'>**Attention!**</font> Use logarithm with base 2 for discounts! Remember that the top1 recommendation shouldn't get discounted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d607a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dcg_score(predictions: np.ndarray, test_interaction_matrix: np.ndarray, topK=10) -> float:\n",
    "    \"\"\"\n",
    "    predictions - np.ndarray - predictions of the recommendation algorithm for each user.\n",
    "    test_interaction_matrix - np.ndarray - test interaction matrix for each user.\n",
    "    \n",
    "    returns - float - mean dcg score over all user.\n",
    "    \"\"\"\n",
    "    score = None\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "    n_users = predictions.shape[0]\n",
    "    discounts = np.log2(np.arange(2, topK+2))\n",
    "    dcg_scores = np.zeros(n_users)\n",
    "    \n",
    "    for user in range(n_users):\n",
    "        top_items = predictions[user][:topK]\n",
    "        relevant_items = test_interaction_matrix[user].nonzero()[0]\n",
    "        relevant_top_items = np.intersect1d(top_items, relevant_items)\n",
    "        relevance = np.zeros(topK)\n",
    "        relevance[np.where(np.isin(top_items, relevant_top_items))] = 1\n",
    "        dcg_scores[user] = np.sum(relevance / discounts[:len(relevance)])\n",
    "    \n",
    "    score = np.mean(dcg_scores)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376794a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([[0, 1, 2, 3], [3, 2, 1, 0]])\n",
    "test_interaction_matrix = np.array([[1, 0, 0, 0], [0, 0, 0, 1]])\n",
    "\n",
    "dcg_score = get_dcg_score(predictions, test_interaction_matrix, topK=4)\n",
    "\n",
    "assert np.isclose(dcg_score, 1), \"1 expected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86afdf65",
   "metadata": {},
   "source": [
    "* Can DCG score be higher than 1? - Yes\n",
    "* Can the average DCG score be higher than 1? - Yes\n",
    "* Why? - The average DCG score can be higher than 1 because it is the sum of discounted relevance scores for all users divided by the total number of users. If the relevance scores are high and the recommended items are ranked well, the resulting DCG scores can be higher than 1, leading to an average DCG score greater than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef924fee",
   "metadata": {},
   "source": [
    "### nDCG Score\n",
    "\n",
    "Following the same parameter convention as for DCG implement nDCG metric.\n",
    "\n",
    "<font color='red'>**Attention!**</font> Remember that ideal DCG is calculated separetely for each user and depends on the number of tracks held out for them as a Test set! Use logarithm with base 2 for discounts! Remember that the top1 recommendation shouldn't get discounted!\n",
    "\n",
    "<font color='red'>**Note:**</font> nDCG is calculated for **every user separately** and then the average is returned. You do not necessarily need to use the function you implemented above. Writing nDCG from scatch might be a good idea as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f2ec6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ndcg_score(predictions: np.ndarray, test_interaction_matrix: np.ndarray, topK=10) -> float:\n",
    "    \"\"\"\n",
    "    predictions - np.ndarray - predictions of the recommendation algorithm for each user.\n",
    "    test_interaction_matrix - np.ndarray - test interaction matrix for each user.\n",
    "    topK - int - topK recommendations should be evaluated.\n",
    "    \n",
    "    returns - average ndcg score over all users.\n",
    "    \"\"\"\n",
    "    score = None\n",
    "    \n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "    n_users = predictions.shape[0]\n",
    "    discounts = np.log2(np.arange(2, topK+2))\n",
    "    ndcg_scores = np.zeros(n_users)\n",
    "    \n",
    "    for user in range(n_users):\n",
    "        top_items = predictions[user][:topK]\n",
    "        relevant_items = test_interaction_matrix[user].nonzero()[0]\n",
    "        relevant_top_items = np.intersect1d(top_items, relevant_items)\n",
    "        relevance = np.zeros(topK)\n",
    "        relevance[np.where(np.isin(top_items, relevant_top_items))] = 1\n",
    "        ideal_relevance = np.zeros(len(relevant_items))\n",
    "        ideal_relevance[0] = 1\n",
    "        ideal_dcg = np.sum(ideal_relevance / discounts[:len(ideal_relevance)])\n",
    "        dcg = np.sum(relevance / discounts[:len(relevance)])\n",
    "        \n",
    "        if ideal_dcg > 0:\n",
    "            ndcg_scores[user] = dcg / ideal_dcg\n",
    "        else:\n",
    "            ndcg_scores[user] = 0\n",
    "    \n",
    "    score = np.mean(ndcg_scores)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4db41b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([[0, 1, 2, 3], [3, 2, 1, 0]])\n",
    "test_interaction_matrix = np.array([[1, 0, 0, 0], [0, 0, 0, 1]])\n",
    "\n",
    "ndcg_score = get_ndcg_score(predictions, test_interaction_matrix, topK=4)\n",
    "\n",
    "assert np.isclose(ndcg_score, 1), \"ndcg score is not correct.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34472609",
   "metadata": {},
   "source": [
    "* Can nDCG score be higher than 1? - No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22655bbf",
   "metadata": {},
   "source": [
    "## <font color='red'>TASK 2/2</font>: Evaluation\n",
    "Use provided rec.py (see imports below) to build a simple evaluation framework. It should be able to evaluate POP, ItemKNN and SVD.\n",
    "\n",
    "*Make sure to place provided rec.py next to your notebook for the imports to work.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222a425e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec import svd_decompose, svd_recommend_to_list  #SVD\n",
    "from rec import inter_matr_implicit\n",
    "from rec import recTopK  #ItemKNN\n",
    "from rec import recTopKPop  #TopPop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6a9b7",
   "metadata": {},
   "source": [
    "Load the users, items and both the train interactions and test interactions\n",
    "from the **new version of the lfm-tiny dataset** provided with the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "276fea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(dataset, file):\n",
    "    return pd.read_csv(dataset + '/' + dataset + '.' + file, sep='\\t')\n",
    "\n",
    "# TODO: YOUR IMPLEMENTATION\n",
    "\n",
    "users = read('lfm-tiny', 'user')\n",
    "items = read('lfm-tiny', 'item')\n",
    "train_inters = read('lfm-tiny', 'inter_train')\n",
    "test_inters = read('lfm-tiny', 'inter_test')\n",
    "\n",
    "train_interaction_matrix = inter_matr_implicit(users=users, items=items, interactions=train_inters,\n",
    "                                               dataset_name=\"lfm-tiny\")\n",
    "test_interaction_matrix = inter_matr_implicit(users=users, items=items, interactions=test_inters,\n",
    "                                              dataset_name=\"lfm-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f21bc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1194, 412)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_interaction_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e414bd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get Recommendations\n",
    "\n",
    "Implement the function below to get recommendations from all 3 recommender algorithms. Make sure you use the provided config dictionary and pay attention to the structure for the output dictionary - we will use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "47964245",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_predict = {\n",
    "    #interaction matrix\n",
    "    \"train_inter\": train_interaction_matrix,\n",
    "    #topK parameter used for all algorithms\n",
    "    \"top_k\": 10,\n",
    "    #specific parameters for all algorithms\n",
    "    \"recommenders\": {\n",
    "        \"SVD\": {\n",
    "            \"n_factors\": 50\n",
    "        },\n",
    "        \"ItemKNN\": {\n",
    "            \"n_neighbours\": 5\n",
    "        },\n",
    "        \"TopPop\": {\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "52b7a07a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_recommendations_for_algorithms(config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    config - dict - configuration as defined above\n",
    "\n",
    "    returns - dict - already predefined below with name \"rec_dict\"\n",
    "    \"\"\"\n",
    "\n",
    "    #use this structure to return results\n",
    "    rec_dict = {\"recommenders\": {\n",
    "        \"SVD\": {\n",
    "            #Add your predictions here\n",
    "            \"recommendations\": np.array([])\n",
    "        },\n",
    "        \"ItemKNN\": {\n",
    "            \"recommendations\": np.array([])\n",
    "        },\n",
    "        \"TopPop\": {\n",
    "            \"recommendations\": np.array([])\n",
    "        },\n",
    "    }}\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "    train_inter = config[\"train_inter\"]\n",
    "    n_users = train_inter.shape[0]\n",
    "    top_k = config[\"top_k\"]\n",
    "    svd_n_factors = config[\"recommenders\"][\"SVD\"][\"n_factors\"]\n",
    "    knn_n_neighbours = config[\"recommenders\"][\"ItemKNN\"][\"n_neighbours\"]\n",
    "    U_final, V_final = svd_decompose(inter_matr=train_inter, f=svd_n_factors)\n",
    "    \n",
    "    svd_predictions = []\n",
    "    knn_predictions = []\n",
    "    pop_predictions = []\n",
    "    \n",
    "    for user in range(n_users):\n",
    "        print(f\"{user + 1}/{n_users}\", end=\"\\r\")\n",
    "        user_svd_prediction = svd_recommend_to_list(user_id=user,\n",
    "                                                seen_item_ids=train_inter[user].nonzero(),\n",
    "                                                U=U_final,\n",
    "                                                V=V_final,\n",
    "                                                topK=top_k)\n",
    "        \n",
    "        user_knn_prediction = recTopK(inter_matr=train_inter,\n",
    "                                      user=user,\n",
    "                                      top_k=top_k,\n",
    "                                      n=knn_n_neighbours)\n",
    "        \n",
    "        user_pop_prediction = recTopKPop(inter_matr=train_inter, \n",
    "                                         user=user, \n",
    "                                         top_k=top_k)\n",
    "        \n",
    "        svd_predictions.append(user_svd_prediction)\n",
    "        knn_predictions.append(user_knn_prediction)\n",
    "        pop_predictions.append(user_pop_prediction)\n",
    "    \n",
    "    svd_predictions = np.array(svd_predictions)\n",
    "    knn_predictions = np.array(knn_predictions)\n",
    "    pop_predictions = np.array(pop_predictions)\n",
    "    \n",
    "    \n",
    "    rec_dict[\"recommenders\"][\"SVD\"][\"recommendations\"] = svd_predictions\n",
    "    rec_dict[\"recommenders\"][\"ItemKNN\"][\"recommendations\"] = knn_predictions\n",
    "    rec_dict[\"recommenders\"][\"TopPop\"][\"recommendations\"] = pop_predictions\n",
    "    \n",
    "\n",
    "    return rec_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0b78eab7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1194/1194\r"
     ]
    }
   ],
   "source": [
    "recommendations = get_recommendations_for_algorithms(config_predict)\n",
    "\n",
    "assert \"SVD\" in recommendations[\"recommenders\"] and \"recommendations\" in recommendations[\"recommenders\"][\"SVD\"]\n",
    "assert isinstance(recommendations[\"recommenders\"][\"SVD\"][\"recommendations\"], np.ndarray)\n",
    "assert \"ItemKNN\" in recommendations[\"recommenders\"] and \"recommendations\" in recommendations[\"recommenders\"][\"ItemKNN\"]\n",
    "assert isinstance(recommendations[\"recommenders\"][\"ItemKNN\"][\"recommendations\"], np.ndarray)\n",
    "assert \"TopPop\" in recommendations[\"recommenders\"] and \"recommendations\" in recommendations[\"recommenders\"][\"TopPop\"]\n",
    "assert isinstance(recommendations[\"recommenders\"][\"TopPop\"][\"recommendations\"], np.ndarray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaf7a88",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate Recommendations\n",
    "\n",
    "Implement the function such that it evaluates the previously generated recommendations. Make sure you use the provided config dictionary and pay attention to the structure for the output dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f7478da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_test = {\n",
    "    \"top_k\": 10,\n",
    "    \"test_inter\": test_interaction_matrix,\n",
    "    \"recommenders\": {}  # here you can access the recommendations from get_recommendations_for_algorithms\n",
    "\n",
    "}\n",
    "# add dictionary with recommendations to config dictionary\n",
    "config_test.update(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "062c0fd0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_algorithms(config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    config - dict - configuration as defined above\n",
    "\n",
    "    returns - dict - { Recommender Key from input dict: { \"ndcg\": float - ndcg from evaluation for this recommender} }\n",
    "    \"\"\"\n",
    "\n",
    "    metrics = {\n",
    "        \"SVD\": {\n",
    "        },\n",
    "        \"ItemKNN\": {\n",
    "        },\n",
    "        \"TopPop\": {\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # TODO: YOUR IMPLEMENTATION.\n",
    "    top_k = config[\"top_k\"]\n",
    "    test_inter = config[\"test_inter\"]\n",
    "    \n",
    "    metrics[\"SVD\"][\"ndcg\"] = get_ndcg_score(predictions=config[\"recommenders\"][\"SVD\"][\"recommendations\"],\n",
    "                                            test_interaction_matrix=test_inter,\n",
    "                                            topK=top_k)\n",
    "    \n",
    "    metrics[\"ItemKNN\"][\"ndcg\"] = get_ndcg_score(predictions=config[\"recommenders\"][\"ItemKNN\"][\"recommendations\"],\n",
    "                                            test_interaction_matrix=test_inter,\n",
    "                                            topK=top_k)\n",
    "    \n",
    "    metrics[\"TopPop\"][\"ndcg\"] = get_ndcg_score(predictions=config[\"recommenders\"][\"TopPop\"][\"recommendations\"],\n",
    "                                            test_interaction_matrix=test_inter,\n",
    "                                            topK=top_k)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36d4b9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluating Every Algorithm\n",
    "Make sure everything works.\n",
    "We expect KNN to outperform other algorithms on our small data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bc0f672c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluations = evaluate_algorithms(config_test)\n",
    "\n",
    "assert \"SVD\" in evaluations and \"ndcg\" in evaluations[\"SVD\"] and isinstance(evaluations[\"SVD\"][\"ndcg\"], float)\n",
    "assert \"ItemKNN\" in evaluations and \"ndcg\" in evaluations[\"ItemKNN\"] and isinstance(evaluations[\"ItemKNN\"][\"ndcg\"], float)\n",
    "assert \"TopPop\" in evaluations and \"ndcg\" in evaluations[\"TopPop\"] and isinstance(evaluations[\"TopPop\"][\"ndcg\"], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "215bfaee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD ndcg: 0.1584739887967836\n",
      "ItemKNN ndcg: 0.27235871317055826\n",
      "TopPop ndcg: 0.1424654348837062\n"
     ]
    }
   ],
   "source": [
    "for recommender in evaluations.keys():\n",
    "    print(f\"{recommender} ndcg: {evaluations[recommender]['ndcg']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191839c",
   "metadata": {},
   "source": [
    "## Questions and Potential Future Work\n",
    "* How would you try improve performance of all three algorithms? - Tune hyperparameters\n",
    "* What other metrics would you consider to compare these recommender systems? - F-measure, Average Precision (AP), Mean Average Precision (MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0f4ad182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The end."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
